{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 2 - Sentiment Analysis Model (Problem 1)</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Build a sentiment analysis model to predict the emoticon for each text input. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoformat code on cell run.\n",
    "%load_ext lab_black\n",
    "# Import the Required Packages\n",
    "import os\n",
    "import gc\n",
    "import mlflow\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from functools import partial\n",
    "from git import Repo\n",
    "from minio import Minio\n",
    "from zipfile import ZipFile\n",
    "from textblob import TextBlob\n",
    "from unidecode import unidecode\n",
    "from emot import emoji, emoticons\n",
    "from tempfile import mkdtemp, NamedTemporaryFile\n",
    "from shutil import rmtree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from gensim.models.fasttext import load_facebook_model, load_facebook_vectors\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, stem_text\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    LeakyReLU,\n",
    "    ReLU,\n",
    "    LSTM,\n",
    "    GRU,\n",
    "    BatchNormalization,\n",
    "    LayerNormalization,\n",
    "    Dense,\n",
    ")\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure access to MLFlow by setting the following environment variables:\n",
    "- `MLFLOW_TRACKING_URI` - URL to the MLFlow Tracking server.\n",
    "- `MLFLOW_S3_ENDPOINT_URL` - URL to the MLFlow S3 Backend Store\n",
    "- `MLFLOW_EXPERIMENT` - Optional. The name of the MLFlow experiment to log to.\n",
    "- `MINIO_HOST` - End to the Minio S3 Store.\n",
    "- `AWS_ACCESS_KEY_ID` - MLFlow S3 backend store Avectorsccess Key ID.\n",
    "- `AWS_SECRET_ACCESS_KEY` - MLFlow S3 backend store secret access key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TF_FORCE_GPU_ALLOW_GROWTH` -  Force Tensorflow to allocate GPU memory dynamically\n",
    "instead of of all at once as a workaround for this\n",
    "[cuDNN failed to initialize issue](https://github.com/tensorflow/tensorflow/issues/24828)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
     ]
    }
   ],
   "source": [
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start MLFlow run with the name of the commit as fthe run name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(os.environ.get(\"MLFLOW_EXPERIMENT\", \"staging\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = Repo(search_parent_directories=True)\n",
    "mlflow.start_run(run_name=repo.head.commit.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup `minio` client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio = Minio(\n",
    "    endpoint=os.environ[\"MINIO_HOST\"],\n",
    "    access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    secure=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 – Data Loading and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '😍', 1: '😂', 2: '📷', 3: '🔥', 4: '❤'}\n",
      "A total of:  5 Emoji Icons\n"
     ]
    }
   ],
   "source": [
    "# Load the emoji_dictionary\n",
    "df = pd.read_csv(f\"{DATA_DIR}/mapping.csv\", delimiter=\",\")\n",
    "emoji_dictionary = df.loc[:, \"emoticons\"].to_dict()\n",
    "print(emoji_dictionary)\n",
    "print(\"A total of: \", len(emoji_dictionary), \"Emoji Icons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the emojis can't be rendered in some situations such as graph plotting, create a mapping for the labels to emoji nameategorical types for the grouping variables to control the order of plot elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_names = {\n",
    "    0: \"heart-eyes\",\n",
    "    1: \"crying-laughing\",\n",
    "    2: \"camera\",\n",
    "    3: \"fire\",\n",
    "    4: \"heart\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(f\"{DATA_DIR}/dataset.csv\", delimiter=\",\")\n",
    "texts = df.loc[:, \"TEXT\"].values\n",
    "labels = df.loc[:, \"Label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the maximum length of the text inputs is  34\n"
     ]
    }
   ],
   "source": [
    "# Check the maximum length of texts\n",
    "max_len = -1\n",
    "for example in texts:\n",
    "    if len(example.split()) > max_len:\n",
    "        max_len = len(example.split())\n",
    "\n",
    "print(\"the maximum length of the text inputs is \", max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first 5 rows of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Been friends since 7th grade. Look at us now w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is what it looks like when someone loves ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @user this white family was invited to a Bl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Westenders @user #LAZzNation @ Weston, Toronto\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maxwell heads home @ Summa Akron City Hospital\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  Label\n",
       "0  Been friends since 7th grade. Look at us now w...      0\n",
       "1  This is what it looks like when someone loves ...      1\n",
       "2  RT @user this white family was invited to a Bl...      1\n",
       "3   Westenders @user #LAZzNation @ Weston, Toronto\\n      2\n",
       "4   Maxwell heads home @ Summa Akron City Hospital\\n      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splice in actual emojis and names to make the data easier to grasp than raw number labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Label</th>\n",
       "      <th>Emoji</th>\n",
       "      <th>EmojiName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Been friends since 7th grade. Look at us now w...</td>\n",
       "      <td>0</td>\n",
       "      <td>😍</td>\n",
       "      <td>heart-eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is what it looks like when someone loves ...</td>\n",
       "      <td>1</td>\n",
       "      <td>😂</td>\n",
       "      <td>crying-laughing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @user this white family was invited to a Bl...</td>\n",
       "      <td>1</td>\n",
       "      <td>😂</td>\n",
       "      <td>crying-laughing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Westenders @user #LAZzNation @ Weston, Toronto\\n</td>\n",
       "      <td>2</td>\n",
       "      <td>📷</td>\n",
       "      <td>camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maxwell heads home @ Summa Akron City Hospital\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>😍</td>\n",
       "      <td>heart-eyes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  Label Emoji  \\\n",
       "0  Been friends since 7th grade. Look at us now w...      0     😍   \n",
       "1  This is what it looks like when someone loves ...      1     😂   \n",
       "2  RT @user this white family was invited to a Bl...      1     😂   \n",
       "3   Westenders @user #LAZzNation @ Weston, Toronto\\n      2     📷   \n",
       "4   Maxwell heads home @ Summa Akron City Hospital\\n      0     😍   \n",
       "\n",
       "         EmojiName  \n",
       "0       heart-eyes  \n",
       "1  crying-laughing  \n",
       "2  crying-laughing  \n",
       "3           camera  \n",
       "4       heart-eyes  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Emoji\"] = df[\"Label\"].map(emoji_dictionary)\n",
    "df[\"EmojiName\"] = df[\"Label\"].map(emoji_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the distribution of the data examples for each Emoji to check for class imbalance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fb9efead898>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(kind=\"count\", data=df, y=\"EmojiName\", aspect=16 / 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "❤    18043\n",
       "😍     8537\n",
       "😂     8247\n",
       "🔥     5223\n",
       "📷     2496\n",
       "Name: Emoji, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Emoji\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The disparty between the number of examples between the different Emojis show a significant class imbalance.\n",
    "- Metrics such as accuracy will not produce accurate results until the class imbalance issue is resolved. [[1]](https://machinelearningmastery.com/failure-of-accuracy-for-imbalanced-class-distributions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glancing through the data examples, one can make the following observations about the data:\n",
    "- Although there are no Emojis used in the data, emoticons such as `:)` or `:(` are present in the text data.\n",
    "- Common contractions ie `w/` to represent `with` are present in the text data.\n",
    "- Stylised words such as `O B E S S E D` will need to be converted its normal `obsessed` equavilent\n",
    "- Location words seem highly indicative that the class should be a 📷\n",
    "- The dataset mentions many locations in the US, as such state contractions such as NY for New York, LA for Los Angles can be safely expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data to train/test subsets reserve 1000 examples for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 5000\n",
    "mlflow.log_param(\"test_size\", n_test)\n",
    "# Split the X & y into train and test set\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"TEXT\"], df[\"Label\"], test_size=n_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning text data**: [[2]](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) [[4]](https://www.sciencedirect.com/science/article/abs/pii/S0957417418303683)\n",
    "- `lower_case` - Convert all text tokens to lower case so that `Happy` and `happy` will appear the same to the model.\n",
    "- `replace_emot` - Replace emoticons such `:)` with their textual equvilent `happy`.\n",
    "- `remove_punc` - Remove punctuations such that `yes!` and `yes` would appear the same to model. Also removes trailing newlines.\n",
    "- `replace_unicode` - Replace unicode symbols such as `α` with `a`.\n",
    "- `replace_abbv` - Replace common abbreviations and contractions by by look up their full forms. Uses [slang.txt](https://raw.githubusercontent.com/Deffro/text-preprocessing-techniques/master/slang.txt)\n",
    "- `stopwords` - Removal of stopwords: meaningless words such as `the`, `a`, that are likely irrelevant to prediction.\n",
    "- `stemming` - Remove inflections from words (ie jump**ing**, jump**ed**, jump**s**,) by steming them. Mutually exclusive with `lemmatization`. Implies `lower_case`.\n",
    "- `lemmatization` - Remove inflections from words by looking up the word's lemma. Mutually exclusive with `stemming`.\n",
    "- TODO: remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(text, mapping):\n",
    "    \"\"\"Replace words in the text that match the key in the mapping dict with its value\"\"\"\n",
    "    for word in TextBlob(text).words:\n",
    "        word = str(word)\n",
    "        if word in mapping:\n",
    "            text = text.replace(word, mapping[word])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download corpora for replacing abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-02 05:35:21--  https://raw.githubusercontent.com/Deffro/text-preprocessing-techniques/master/slang.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.8.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.8.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5181 (5.1K) [text/plain]\n",
      "Saving to: ‘slang.txt’\n",
      "\n",
      "slang.txt           100%[===================>]   5.06K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-02-02 05:35:21 (119 MB/s) - ‘slang.txt’ saved [5181/5181]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/Deffro/text-preprocessing-techniques/master/slang.txt -O slang.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-02 05:35:22--  https://gist.githubusercontent.com/rugbyprof/76575b470b6772ce8fa0c49e23931d97/raw/eb731ce40f9c7c032f4db42e96889a3adbe54f8e/states.py\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.8.133\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.8.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1091 (1.1K) [text/plain]\n",
      "Saving to: ‘states.py’\n",
      "\n",
      "states.py           100%[===================>]   1.07K  --.-KB/s    in 0.003s  \n",
      "\n",
      "2021-02-02 05:35:22 (371 KB/s) - ‘states.py’ saved [1091/1091]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://gist.githubusercontent.com/rugbyprof/76575b470b6772ce8fa0c49e23931d97/raw/eb731ce40f9c7c032f4db42e96889a3adbe54f8e/states.py -O states.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_params = {\n",
    "    \"lower_case\": True,\n",
    "    \"replace_emot\": True,\n",
    "    \"remove_punc\": True,\n",
    "    \"replace_unicode\": True,\n",
    "    \"replace_abbv\": True,\n",
    "    \"stopwords\": True,\n",
    "    \"stemming\": False,\n",
    "    \"lemmatization\": True,\n",
    "}\n",
    "mlflow.log_params(clean_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from states import states as states_map\n",
    "\n",
    "\n",
    "def clean_texts(texts, clean_params):\n",
    "    \"\"\"Cleans the given texts applying clean techniques specified in clean_params\n",
    "    Returns:\n",
    "        The given texts with clean techniques applied\n",
    "    \"\"\"\n",
    "    # check mutually exclusive parameters\n",
    "    assert not (clean_params[\"stemming\"] and clean_params[\"lemmatization\"])\n",
    "\n",
    "    # remove trailing newlines\n",
    "    texts = np.asarray([t.rstrip() for t in texts])\n",
    "\n",
    "    # apply cleaning techniques on copy of dataframe\n",
    "    if clean_params[\"lower_case\"]:\n",
    "        texts = np.asarray([t.lower() for t in texts])\n",
    "\n",
    "    if clean_params[\"replace_emot\"]:\n",
    "\n",
    "        def replace_emot(text):\n",
    "            # replace emoticons with meaning if present\n",
    "            results = emoticons(text)\n",
    "            if results[\"flag\"]:\n",
    "                for location, meaning in zip(results[\"location\"], results[\"mean\"]):\n",
    "                    start, end = location\n",
    "                    # fix \"andry\" spelling mistake\n",
    "                    # https://github.com/NeelShah18/emot/pull/19/files\n",
    "                    meaning = meaning.replace(\"andry\", \"angry\")\n",
    "                    text = f\"{text[:start]} {meaning} {text[end+1:]}\"\n",
    "            return text\n",
    "\n",
    "        texts = np.asarray([replace_emot(t) for t in texts])\n",
    "\n",
    "    if clean_params[\"remove_punc\"]:\n",
    "        # … not recognized as puncuation, so remove it manually\n",
    "        texts = np.asarray([strip_punctuation(t.replace(\"…\", \"\")) for t in texts])\n",
    "\n",
    "    if clean_params[\"replace_unicode\"]:\n",
    "        texts = np.asarray([unidecode(t) for t in texts])\n",
    "\n",
    "    if clean_params[\"replace_abbv\"]:\n",
    "        # use utf-sig to fix escape characters\n",
    "        with open(\"slang.txt\", \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            lines = f.readlines()\n",
    "        abbv_pairs = [tuple(line.split(maxsplit=1)) for line in lines]\n",
    "        # remove trailing newlines\n",
    "        abbv_map = {\n",
    "            # \\xa0 - for some reason latin spaces are present, replace with normal spaces.\n",
    "            abbv: full.rstrip().replace(\"\\xa0\", \"\")\n",
    "            for abbv, full in abbv_pairs\n",
    "        }\n",
    "        # additional abbreviation entries\n",
    "        abbv_map.update(\n",
    "            {\n",
    "                \"em\": \"them\",\n",
    "                \"v\": \"very\",\n",
    "            }\n",
    "        )\n",
    "        # expand  US state abbreviations\n",
    "        abbv_map.update(\n",
    "            {code.lower(): name.lower() for code, name in states_map.items()}\n",
    "        )\n",
    "        texts = np.asarray([replace(t, abbv_map) for t in texts])\n",
    "\n",
    "    if clean_params[\"stopwords\"]:\n",
    "        texts = np.asarray([remove_stopwords(t) for t in texts])\n",
    "    if clean_params[\"stemming\"]:\n",
    "        texts = np.asarray([stem_text(t) for t in texts])\n",
    "    if clean_params[\"lemmatization\"]:\n",
    "\n",
    "        def lemmatize(text):\n",
    "            lemma_map = {str(w): w.lemmatize() for w in TextBlob(text).words}\n",
    "            return replace(text, lemma_map)\n",
    "\n",
    "        texts = np.asarray([lemmatize(t) for t in texts])\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 98.4 ms, total: 24 s\n",
      "Wall time: 24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_train_texts = clean_texts(train_texts, clean_params)\n",
    "clean_test_texts = clean_texts(test_texts, clean_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm slang.txt states.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Inspect the clean text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting text into vectors**:\n",
    "- `count` - Use the word count to vectorize text. Uses SVD to condense sparse vectors generated. [[5]](https://stackoverflow.com/a/34726420)\n",
    "- `tfidf` - Use tf-idf to vectorize text. Uses SVD to condense sparse vectors generated. [[5]](https://stackoverflow.com/a/34726420)\n",
    "- `fasttext` - Use pretrained english fasttext model to vectorize text. [[6]](https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md)\n",
    "\n",
    "> Out of an interest for time, `word2vec` is not included as`word2vec` vectors are significantly worst as compared to `fasttext` [[3]](https://github.com/RaRe-Technologies/gensim/blob/ba1ce894a5192fc493a865c535202695bb3c0424/docs/notebooks/Word2Vec_FastText_Comparison.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load pretrained fastext vectors pretrained on common crawl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 926 ms, sys: 3.21 s, total: 4.13 s\n",
      "Wall time: 5.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<minio.datatypes.Object at 0x7fba0ffa6be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# pull pretrained vectors from MINIO cache\n",
    "minio.fget_object(\n",
    "    bucket_name=\"cache\",\n",
    "    object_name=\"pretrained/fasttext/cc.en.bin\",\n",
    "    file_path=\"cc.en.bin\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.4 s, sys: 12.9 s, total: 1min 7s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "fasttext_vecs = load_facebook_vectors(\"cc.en.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute max no. of words per data example\n",
    "max_n_words = max(\n",
    "    [len(t.split()) for t in np.concatenate((clean_train_texts, clean_test_texts))]\n",
    ")\n",
    "vectorize_params = {\n",
    "    \"vectorize_method\": \"fasttext\",\n",
    "    \"vector_shape\": (max_n_words, 300),\n",
    "}\n",
    "# mlflow.log_params(vectorize_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_texts(texts, corpus_texts, method, vector_shape):\n",
    "    \"\"\"\n",
    "    Vectorize the given texts into 2D feature matrix using the given method.\n",
    "    Args:\n",
    "        texts: Iterable collection of texts to vectorize.\n",
    "        corpus_texts: Vectorization methods are allowed to fit on this corpus.\n",
    "        method: Name of the method to use for vectorization\n",
    "        vector_shape: Shape of the 2D feature matrix generated for each data example\n",
    "            in the form (n_words, n_features)\n",
    "    Returns vector representation of the given texts.\n",
    "    \"\"\"\n",
    "\n",
    "    if method in [\"count\", \"tfidf\"]:\n",
    "        if method == \"count\":\n",
    "            count = CountVectorizer()\n",
    "            count.fit(corpus_texts)\n",
    "            sparse_vecs = count.transform(texts)\n",
    "            # TODO: expand dims\n",
    "        elif method == \"tfidf\":\n",
    "            tfidf = TfidfVectorizer()\n",
    "            tfidf.fit(corpus_texts)\n",
    "            sparse_vecs = tfidf.transform(texts)\n",
    "        # use svd to condense vectors to match target vector len\n",
    "        svd = TruncatedSVD(n_components=vector_shape[1])\n",
    "        text_vecs = svd.fit_transform(sparse_vecs)\n",
    "        # since both count and tfidf are bag of words representations, add the missing\n",
    "        # word dimension here: (examples, features) -> (examples, word, features)\n",
    "        text_vecs = np.expand_dims(text_vecs, axis=1)\n",
    "    elif method == \"fasttext\":\n",
    "\n",
    "        def vectorize_fasttext(text):\n",
    "            # convert only the the first vector_shape[0] words\n",
    "            convert_words = text.split()[: vector_shape[0]]\n",
    "            # handle case where convert_words are empty\n",
    "            if len(convert_words) <= 0:\n",
    "                convert_words = [\"???\"]\n",
    "            word_vecs = [fasttext_vecs[w] for w in convert_words]\n",
    "            return np.asarray(word_vecs)\n",
    "\n",
    "        text_vecs = [vectorize_fasttext(t) for t in texts]\n",
    "        # pad words dimension to match vector_shape[0]\n",
    "        text_vecs = [\n",
    "            np.pad(\n",
    "                v, [(0, max(0, vector_shape[0] - v.shape[0])), (0, 0)], mode=\"constant\"\n",
    "            )\n",
    "            for v in text_vecs\n",
    "        ]\n",
    "        text_vecs = np.asarray(text_vecs)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Vectorization method not supported: {method}\")\n",
    "\n",
    "    # pad the text vec with zeros if we dont meet target vector shape\n",
    "    pad_words_len = max(0, vector_shape[0] - text_vecs.shape[1])\n",
    "    pad_features_len = max(0, vector_shape[1] - text_vecs.shape[2])\n",
    "    text_vecs = np.pad(\n",
    "        text_vecs, [(0, 0), (0, pad_words_len), (0, pad_features_len)], mode=\"constant\"\n",
    "    )\n",
    "    return text_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.2 s, sys: 616 ms, total: 3.81 s\n",
      "Wall time: 3.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_text_vecs = vectorize_texts(\n",
    "    clean_train_texts,\n",
    "    corpus_texts=clean_train_texts,\n",
    "    method=vectorize_params[\"vectorize_method\"],\n",
    "    vector_shape=vectorize_params[\"vector_shape\"],\n",
    ")\n",
    "\n",
    "test_text_vecs = vectorize_texts(\n",
    "    clean_test_texts,\n",
    "    corpus_texts=clean_test_texts,\n",
    "    method=vectorize_params[\"vectorize_method\"],\n",
    "    vector_shape=vectorize_params[\"vector_shape\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2573"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free memory used to store vectors\n",
    "del fasttext_vecs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf cc.en.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Inspect the vectors derived form text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One hot encode labels**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_one_hot = to_categorical(train_labels)\n",
    "test_labels_one_hot = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combat the class imbalance issue we can resample the training set [[7]](https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb):\n",
    "- `oversample` : Use Random Oversampling to duplicate the data examples for Emojis smaller no. of examples to match the majority class.\n",
    "- `undersample`: Use Random Undersampling to undersample the data examples for the Majority Emoji cass to match the minority class.\n",
    "- `SMOTE`: Interpolate new systhesised training examples between K nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_method = \"oversample\"\n",
    "# mlflow.log_param(\"sampling_method\", sampling_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(text_vecs, labels, method):\n",
    "    \"\"\"\n",
    "    Resample data using the following resampling method to resolve class imbalance.\n",
    "    Args:\n",
    "        text_vecs: Text Vectors in the\n",
    "        method: The resampling method to use.\n",
    "    Returns:\n",
    "        The resampled texts and labels\n",
    "    \"\"\"\n",
    "    resamplers = {\n",
    "        \"oversample\": RandomOverSampler(),\n",
    "        \"undersample\": RandomUnderSampler(),\n",
    "        \"smote\": SMOTE(),\n",
    "    }\n",
    "\n",
    "    if method not in resamplers:\n",
    "        raise NotImplementedError(f\"Resampling method not supported: {method}\")\n",
    "    resampler = resamplers[method]\n",
    "    # flatten word, features dimensions into features dimension\n",
    "    # as imblearn only supports 2D as inputs\n",
    "    vector_shape = text_vecs.shape[1:]\n",
    "    flat_text_vecs = np.reshape(text_vecs, (len(text_vecs), -1))\n",
    "    flat_text_vecs, labels = resampler.fit_resample(flat_text_vecs, labels)\n",
    "    # restore word, features dimensions\n",
    "    text_vecs = np.reshape(flat_text_vecs, (len(flat_text_vecs),) + vector_shape)\n",
    "    return text_vecs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_vecs_sampled, train_labels_sampled = resample_data(\n",
    "    train_text_vecs, train_labels, \"oversample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training label distribution to check that  class imbalance issue has been resolved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fba0fe03e80>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(kind=\"count\", x=\"Label\", data=pd.DataFrame(train_labels_sampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37546, 5, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 – Develop a Sentiment Analysis Modesl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility functions for building a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier(\n",
    "    in_op,\n",
    "    n_dense_units=128,\n",
    "    n_classes=10,\n",
    "    use_batch_norm=True,\n",
    "    dropout_prob=0.0,\n",
    "    l2_reg=None,\n",
    "    dense_activation=\"relu\",\n",
    "    **activation_params,\n",
    "):\n",
    "    \"\"\"Append a dense classfier block to the given in_op\"\"\"\n",
    "    x = in_op\n",
    "\n",
    "    # disable hidden dense layer if n_dense_units < 1\n",
    "    if n_dense_units >= 1:\n",
    "        x = Dense(\n",
    "            units=n_dense_units,\n",
    "            kernel_regularizer=None if l2_reg is None else l2(l=l2_reg),\n",
    "        )(x)\n",
    "\n",
    "        if use_batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation(dense_activation)(x)\n",
    "    # classifier output layer\n",
    "    x = Dense(\n",
    "        units=n_classes,\n",
    "        activation=\"softmax\",\n",
    "        kernel_regularizer=None if l2_reg is None else l2(l=l2_reg),\n",
    "    )(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_block(\n",
    "    in_op,\n",
    "    rnn_cell=\"lstm\",\n",
    "    n_rnn_units=64,\n",
    "    rnn_activation=\"tanh\",\n",
    "    use_layer_norm=True,\n",
    "    return_sequences=False,\n",
    "    dropout_prob=0.0,\n",
    "    l2_reg=None,\n",
    "    **activation_params,\n",
    "):\n",
    "    rnn_params = {\n",
    "        \"units\": n_rnn_units,\n",
    "        \"activation\": rnn_activation,\n",
    "        \"recurrent_dropout\": dropout_prob,\n",
    "        \"kernel_regularizer\": None if l2_reg is None else l2(l=l2_reg),\n",
    "        \"return_sequences\": return_sequences,\n",
    "    }\n",
    "\n",
    "    x = in_op\n",
    "    if rnn_cell == \"lstm\":\n",
    "        x = LSTM(**rnn_params)(x)\n",
    "    elif rnn_cell == \"gru\":\n",
    "        x = GRU(**rnn_params)(x)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unsupported RNN cell: {rnn_cell}\")\n",
    "\n",
    "    if use_layer_norm:\n",
    "        x = LayerNormalization()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape=vectorize_params[\"vector_shape\"],\n",
    "    n_classes=10,\n",
    "    n_dense_units=0,\n",
    "    use_batch_norm=True,\n",
    "    rnn_cell=\"lstm\",\n",
    "    n_rnn_layers=3,\n",
    "    n_rnn_units=64,\n",
    "    rnn_activation=\"tanh\",\n",
    "    dense_activation=\"relu\",\n",
    "    use_layer_norm=True,\n",
    "    **block_params\n",
    "):\n",
    "    in_op = Input(shape=input_shape)\n",
    "    x = in_op\n",
    "\n",
    "    for i_layer in range(1, n_rnn_layers + 1):\n",
    "        x = rnn_block(\n",
    "            in_op=x,\n",
    "            rnn_cell=rnn_cell,\n",
    "            n_rnn_units=n_rnn_units,\n",
    "            rnn_activation=rnn_activation,\n",
    "            use_layer_norm=use_layer_norm,\n",
    "            # return sequences except last rnn layer\n",
    "            return_sequences=True if i_layer < n_rnn_layers else False,\n",
    "            **block_params,\n",
    "        )\n",
    "\n",
    "    x = dense_classifier(\n",
    "        in_op=x,\n",
    "        n_classes=n_classes,\n",
    "        n_dense_units=n_dense_units,\n",
    "        use_batch_norm=use_batch_norm,\n",
    "        dense_activation=dense_activation,\n",
    "        **block_params,\n",
    "    )\n",
    "\n",
    "    return Model(\n",
    "        inputs=in_op,\n",
    "        outputs=x,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 300)]         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32, 64)            93440     \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 32, 64)            128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32, 64)            33024     \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 32, 64)            128       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, 64)                128       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 160,522\n",
      "Trainable params: 160,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define callbacks to add custom functionality during training:\n",
    "- `TensorBoard` callback records training progress for later viewing with tensorboard.\n",
    "- `ReduceLROnPlateau` callback reduces learning rate when the model is \n",
    "    stuck (ie `val_loss` does not move for `patience` epochs).\n",
    "- `mlflow_log` custom callback logs params, metrics and trained model  to MLFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_callbacks(reduce_lr_stuck, reduce_lr_patience, reduce_lr_factor):\n",
    "    # compile callbacks\n",
    "    callbacks = []\n",
    "    # callback to log tensorboard\n",
    "    log_dir = mkdtemp()\n",
    "    tensorboard = TensorBoard(log_dir=log_dir)\n",
    "    callbacks.append(tensorboard)\n",
    "\n",
    "    # callback to reduce lr on stuck on plateau\n",
    "    mlflow.log_param(\"reduce_lr_stuck\", reduce_lr_stuck)\n",
    "    if reduce_lr_stuck:\n",
    "        callbacks.append(\n",
    "            ReduceLROnPlateau(\n",
    "                factor=reduce_lr_factor,\n",
    "                patience=reduce_lr_patience,\n",
    "                monitor=\"loss\",\n",
    "            )\n",
    "        )\n",
    "        mlflow.log_params(\n",
    "            {\n",
    "                \"reduce_lr_factor\": reduce_lr_factor,\n",
    "                \"reduce_lr_patience\": reduce_lr_patience,\n",
    "            }\n",
    "        )\n",
    "    # callback to log to tensorboard during model training\n",
    "    def on_epoch_end(n_epoch, logs):\n",
    "        mlflow.log_metrics(logs, step=n_epoch)\n",
    "\n",
    "    def on_train_end(logs=None):\n",
    "        # due to this issue https://github.com/tensorflow/tensorflow/issues/38498\n",
    "        # logs is always none.\n",
    "        mlflow.log_artifacts(log_dir, \"tensorboard_logs\")\n",
    "        rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "    mlflow_log = LambdaCallback(\n",
    "        on_epoch_end=on_epoch_end,\n",
    "        on_train_end=on_train_end,\n",
    "    )\n",
    "    callbacks.append(mlflow_log)\n",
    "    return callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting the building blocks together to build a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(\n",
    "    emoji_dictionary,\n",
    "    train_text_vecs,\n",
    "    train_labels_one_hot,\n",
    "    test_text_vecs,\n",
    "    test_labels_one_hot,\n",
    "    build_model_fn=build_model,\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    optimizer=\"adam\",\n",
    "    sgd_momentum=0.9,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "    ],\n",
    "    img_size=(256, 256),\n",
    "    reduce_lr_stuck=False,\n",
    "    reduce_lr_patience=5,\n",
    "    reduce_lr_factor=0.1,\n",
    "    batch_size=32,\n",
    "    run_name=None,\n",
    "    **build_params,\n",
    "):\n",
    "\n",
    "    # build model\n",
    "    model = build_model_fn(n_classes=len(emoji_dictionary), **build_params)\n",
    "    mlflow.log_params(build_params)\n",
    "\n",
    "    # write summary to mlflow\n",
    "    temp_dir = mkdtemp()\n",
    "    summary_fpath = os.path.join(temp_dir, \"summary.txt\")\n",
    "    with open(summary_fpath, \"w\") as f:\n",
    "        model.summary(print_fn=(lambda line: f.write(f\"{line}\\n\")))\n",
    "    mlflow.log_artifact(summary_fpath)\n",
    "    rmtree(temp_dir)\n",
    "\n",
    "    # compile model\n",
    "    optimizers = {\n",
    "        \"adam\": Adam(learning_rate=lr),\n",
    "        \"rmsprop\": RMSprop(learning_rate=lr),\n",
    "        \"sgd\": SGD(learning_rate=lr, momentum=sgd_momentum),\n",
    "    }\n",
    "    model.compile(\n",
    "        optimizer=optimizers[optimizer],\n",
    "        loss=loss,\n",
    "        metrics=metrics,\n",
    "    )\n",
    "    mlflow.log_params(\n",
    "        {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"loss\": loss,\n",
    "            \"metrics\": metrics,\n",
    "            \"learning_rate\": lr,\n",
    "        }\n",
    "    )\n",
    "    if optimizer == \"sgd\":\n",
    "        mlflow.log_param(\"sgd_momentum\", sgd_momentum)\n",
    "\n",
    "    # train model\n",
    "    callbacks = compile_callbacks(\n",
    "        reduce_lr_stuck=reduce_lr_stuck,\n",
    "        reduce_lr_factor=reduce_lr_factor,\n",
    "        reduce_lr_patience=reduce_lr_patience,\n",
    "    )\n",
    "    hist = model.fit(\n",
    "        train_text_vecs,\n",
    "        train_labels_one_hot,\n",
    "        validation_split=0.1,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "    mlflow.keras.log_model(model, \"models\")\n",
    "    mlflow.log_param(\"fit_epochs\", epochs)\n",
    "\n",
    "    # evaluate model\n",
    "    test_metrics = model.evaluate(test_text_vecs, test_labels_one_hot, verbose=2)\n",
    "    # prefix metrics names with test to indicate computed on test set\n",
    "    test_metric_names = [\"test_\" + name for name in model.metrics_names]\n",
    "    mlflow.log_metrics(dict(zip(test_metric_names, test_metrics)))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33791 samples, validate on 3755 samples\n",
      "33791/33791 [==============================] - 22s 662us/sample - loss: 1.1161 - accuracy: 0.5265 - val_loss: 1.0250 - val_accuracy: 0.5806\n",
      "5000/5000 - 1s - loss: 1.0483 - accuracy: 0.5588\n"
     ]
    }
   ],
   "source": [
    "lstm_model = train_eval_model(\n",
    "    emoji_dictionary=emoji_dictionary,\n",
    "    train_text_vecs=train_text_vecs,\n",
    "    train_labels_one_hot=train_labels_one_hot,\n",
    "    test_text_vecs=test_text_vecs,\n",
    "    test_labels_one_hot=test_labels_one_hot,\n",
    "    build_model_fn=build_model,\n",
    "    run_name=None,\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    optimizer=\"adam\",\n",
    "    sgd_momentum=0.9,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "    ],\n",
    "    reduce_lr_stuck=False,\n",
    "    reduce_lr_patience=5,\n",
    "    reduce_lr_factor=0.1,\n",
    "    batch_size=32,\n",
    "    dropout_prob=0.2,\n",
    "    l2_reg=None,\n",
    "    rnn_cell=\"lstm\",\n",
    "    n_rnn_units=64,\n",
    "    rnn_activation=\"tanh\",\n",
    "    use_layer_norm=True,\n",
    "    n_dense_units=128,\n",
    "    use_batch_norm=True,\n",
    "    dense_activation=\"relu\",\n",
    ")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 – Evaluate the Model using Testing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #1 (replicate where necessary for other models)\n",
    "# model.load_weights('text_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Best Model\n",
    "# model.save('text_model_best.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 – Use the Best Model to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('text_model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the user input\n",
    "# text_input = np.array([input()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the user input into numeric tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model output using predict function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [1] Failure of Classification Accuracy for Imbalanced Class Distributions. (2021, January 21). Retrieved from https://machinelearningmastery.com/failure-of-accuracy-for-imbalanced-class-distributions  \n",
    "- [2] sudalairajkumar. (2019). Getting started with Text Preprocessing. Kaggle. Retrieved from https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing\n",
    "- [3] RaRe-Technologies. (2021, January 28). gensim. Retrieved from https://github.com/RaRe-Technologies/gensim/blob/ba1ce894a5192fc493a865c535202695bb3c0424/docs/notebooks/Word2Vec_FastText_Comparison.ipynb\n",
    "- [4] Symeonidis, S., Effrosynidis, D., & Arampatzis, A. (2018). A comparative evaluation of pre-processing techniques and their interactions for twitter sentiment analysis. Expert Syst. Appl., 110, 298–310. doi: 10.1016/j.eswa.2018.06.022\n",
    "- [5] is it possible Apply PCA on any Text Classification? (2021, January 31). Retrieved from https://stackoverflow.com/questions/34725726/is-it-possible-apply-pca-on-any-text-classification\n",
    "- [6] facebookresearch. (2021, February 01). fastText. Retrieved from https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md\n",
    "- [7] Badr, W. (2020). Having an Imbalanced Dataset? Here Is How You Can Fix It. Towards Data Science. Retrieved from https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "core.harbor.mrzzy.co/kf-jupyter/tf-gpu-dl-plugged:0.4.0",
   "experiment": {
    "id": "new",
    "name": "test2"
   },
   "experiment_name": "test2",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "test",
   "snapshot_volumes": false,
   "steps_defaults": [
    "label:uses-minio:true",
    "label:uses-mlflow:true"
   ],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
