{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 2 - Sentiment Analysis Model (Problem 1)</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Build a sentiment analysis model to predict the emoticon for each text input. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "# autoformat code on cell run.\n",
    "%load_ext lab_black\n",
    "# Import the Required Packages\n",
    "import os\n",
    "import gc\n",
    "import mlflow\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from functools import partial\n",
    "from git import Repo\n",
    "from minio import Minio\n",
    "from zipfile import ZipFile\n",
    "from textblob import TextBlob\n",
    "from unidecode import unidecode\n",
    "from emot import emoji, emoticons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from gensim.models.fasttext import load_facebook_model, load_facebook_vectors\n",
    "from gensim.models.wrappers import FastText\n",
    "from gensim.parsing.preprocessing import remove_stopwords, strip_punctuation, stem_text\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    LeakyReLU,\n",
    "    ReLU,\n",
    "    LSTM,\n",
    "    GRU,\n",
    "    BatchNormalization,\n",
    "    LayerNormalization,\n",
    "    Dense,\n",
    ")\n",
    "from tensorflow.keras.activations import tanh, selu\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure access to MLFlow by setting the following environment variables:\n",
    "- `MLFLOW_TRACKING_URI` - URL to the MLFlow Tracking server.\n",
    "- `MLFLOW_S3_ENDPOINT_URL` - URL to the MLFlow S3 Backend Store\n",
    "- `MLFLOW_EXPERIMENT` - Optional. The name of the MLFlow experiment to log to.\n",
    "- `MINIO_HOST` - End to the Minio S3 Store.\n",
    "- `AWS_ACCESS_KEY_ID` - MLFlow S3 backend store Avectorsccess Key ID.\n",
    "- `AWS_SECRET_ACCESS_KEY` - MLFlow S3 backend store secret access key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TF_FORCE_GPU_ALLOW_GROWTH` -  Force Tensorflow to allocate GPU memory dynamically\n",
    "instead of of all at once as a workaround for this\n",
    "[cuDNN failed to initialize issue](https://github.com/tensorflow/tensorflow/issues/24828)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
     ]
    }
   ],
   "source": [
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start MLFlow run with the name of the commit as fthe run name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(os.environ.get(\"MLFLOW_EXPERIMENT\", \"staging\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = Repo(search_parent_directories=True)\n",
    "mlflow.start_run(run_name=repo.head.commit.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup `minio` client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio = Minio(\n",
    "    endpoint=os.environ[\"MINIO_HOST\"],\n",
    "    access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    secure=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 ‚Äì Data Loading and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'üòç', 1: 'üòÇ', 2: 'üì∑', 3: 'üî•', 4: '‚ù§'}\n",
      "A total of:  5 Emoji Icons\n"
     ]
    }
   ],
   "source": [
    "# Load the emoji_dictionary\n",
    "df = pd.read_csv(f\"{DATA_DIR}/mapping.csv\", delimiter=\",\")\n",
    "emoji_dictionary = df.loc[:, \"emoticons\"].to_dict()\n",
    "print(emoji_dictionary)\n",
    "print(\"A total of: \", len(emoji_dictionary), \"Emoji Icons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the emojis can't be rendered in some situations such as graph plotting, create a mapping for the labels to emoji nameategorical types for the grouping variables to control the order of plot elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_names = {\n",
    "    0: \"heart-eyes\",\n",
    "    1: \"crying-laughing\",\n",
    "    2: \"camera\",\n",
    "    3: \"fire\",\n",
    "    4: \"heart\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "df = pd.read_csv(f\"{DATA_DIR}/dataset.csv\", delimiter=\",\")\n",
    "texts = df.loc[:, \"TEXT\"].values\n",
    "labels = df.loc[:, \"Label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the maximum length of the text inputs is  34\n"
     ]
    }
   ],
   "source": [
    "# Check the maximum length of texts\n",
    "max_len = -1\n",
    "for example in texts:\n",
    "    if len(example.split()) > max_len:\n",
    "        max_len = len(example.split())\n",
    "\n",
    "print(\"the maximum length of the text inputs is \", max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the first 5 rows of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Been friends since 7th grade. Look at us now w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is what it looks like when someone loves ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @user this white family was invited to a Bl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Westenders @user #LAZzNation @ Weston, Toronto\\n</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maxwell heads home @ Summa Akron City Hospital\\n</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  Label\n",
       "0  Been friends since 7th grade. Look at us now w...      0\n",
       "1  This is what it looks like when someone loves ...      1\n",
       "2  RT @user this white family was invited to a Bl...      1\n",
       "3   Westenders @user #LAZzNation @ Weston, Toronto\\n      2\n",
       "4   Maxwell heads home @ Summa Akron City Hospital\\n      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splice in actual emojis and names to make the data easier to grasp than raw number labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEXT</th>\n",
       "      <th>Label</th>\n",
       "      <th>Emoji</th>\n",
       "      <th>EmojiName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Been friends since 7th grade. Look at us now w...</td>\n",
       "      <td>0</td>\n",
       "      <td>üòç</td>\n",
       "      <td>heart-eyes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is what it looks like when someone loves ...</td>\n",
       "      <td>1</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>crying-laughing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @user this white family was invited to a Bl...</td>\n",
       "      <td>1</td>\n",
       "      <td>üòÇ</td>\n",
       "      <td>crying-laughing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Westenders @user #LAZzNation @ Weston, Toronto\\n</td>\n",
       "      <td>2</td>\n",
       "      <td>üì∑</td>\n",
       "      <td>camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Maxwell heads home @ Summa Akron City Hospital\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>üòç</td>\n",
       "      <td>heart-eyes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TEXT  Label Emoji  \\\n",
       "0  Been friends since 7th grade. Look at us now w...      0     üòç   \n",
       "1  This is what it looks like when someone loves ...      1     üòÇ   \n",
       "2  RT @user this white family was invited to a Bl...      1     üòÇ   \n",
       "3   Westenders @user #LAZzNation @ Weston, Toronto\\n      2     üì∑   \n",
       "4   Maxwell heads home @ Summa Akron City Hospital\\n      0     üòç   \n",
       "\n",
       "         EmojiName  \n",
       "0       heart-eyes  \n",
       "1  crying-laughing  \n",
       "2  crying-laughing  \n",
       "3           camera  \n",
       "4       heart-eyes  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Emoji\"] = df[\"Label\"].map(emoji_dictionary)\n",
    "df[\"EmojiName\"] = df[\"Label\"].map(emoji_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise the distribution of the data examples for each Emoji to check for class imbalance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f3ecfcc3b38>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(kind=\"count\", data=df, y=\"EmojiName\", aspect=16 / 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚ù§    18043\n",
       "üòç     8537\n",
       "üòÇ     8247\n",
       "üî•     5223\n",
       "üì∑     2496\n",
       "Name: Emoji, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Emoji\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- The disparty between the number of examples between the different Emojis show a significant class imbalance.\n",
    "- Metrics such as accuracy will not produce accurate results until the class imbalance issue is resolved. [[1]](https://machinelearningmastery.com/failure-of-accuracy-for-imbalanced-class-distributions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glancing through the data examples, one can make the following observations about the data:\n",
    "- Although there are no Emojis used in the data, emoticons such as `:)` or `:(` are present in the text data.\n",
    "- Common contractions ie `w/` to represent `with` are present in the text data.\n",
    "- Stylised words such as `O B E S S E D` will need to be converted its normal `obsessed` equavilent\n",
    "- Location words seem highly indicative that the class should be a üì∑\n",
    "- The dataset mentions many locations in the US, as such state contractions such as NY for New York, LA for Los Angles can be safely expanded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data to train/test subsets reserve 1000 examples for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 5000\n",
    "mlflow.log_param(\"test_size\", n_test)\n",
    "# Split the X & y into train and test set\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df[\"TEXT\"], df[\"Label\"], test_size=n_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning text data**: [[2]](https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing) [[4]](https://www.sciencedirect.com/science/article/abs/pii/S0957417418303683)\n",
    "- `lower_case` - Convert all text tokens to lower case so that `Happy` and `happy` will appear the same to the model.\n",
    "- `replace_emot` - Replace emoticons such `:)` with their textual equvilent `happy`.\n",
    "- `remove_punc` - Remove punctuations such that `yes!` and `yes` would appear the same to model. Also removes trailing newlines.\n",
    "- `replace_unicode` - Replace unicode symbols such as `Œ±` with `a`.\n",
    "- `replace_abbv` - Replace common abbreviations and contractions by by look up their full forms. Uses [slang.txt](https://raw.githubusercontent.com/Deffro/text-preprocessing-techniques/master/slang.txt)\n",
    "- `stopwords` - Removal of stopwords: meaningless words such as `the`, `a`, that are likely irrelevant to prediction.\n",
    "- `stemming` - Remove inflections from words (ie jump**ing**, jump**ed**, jump**s**,) by steming them. Mutually exclusive with `lemmatization`. Implies `lower_case`.\n",
    "- `lemmatization` - Remove inflections from words by looking up the word's lemma. Mutually exclusive with `stemming`.\n",
    "- TODO: remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace(text, mapping):\n",
    "    \"\"\"Replace words in the text that match the key in the mapping dict with its value\"\"\"\n",
    "    for word in TextBlob(text).words:\n",
    "        word = str(word)\n",
    "        if word in mapping:\n",
    "            text = text.replace(word, mapping[word])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download corpora for replacing abbreviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-02 03:04:15--  https://raw.githubusercontent.com/Deffro/text-preprocessing-techniques/master/slang.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.8.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.8.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5181 (5.1K) [text/plain]\n",
      "Saving to: ‚Äòslang.txt‚Äô\n",
      "\n",
      "slang.txt           100%[===================>]   5.06K  --.-KB/s    in 0.001s  \n",
      "\n",
      "2021-02-02 03:04:15 (5.05 MB/s) - ‚Äòslang.txt‚Äô saved [5181/5181]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/Deffro/text-preprocessing-techniques/master/slang.txt -O slang.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-02 03:04:15--  https://gist.githubusercontent.com/rugbyprof/76575b470b6772ce8fa0c49e23931d97/raw/eb731ce40f9c7c032f4db42e96889a3adbe54f8e/states.py\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.8.133\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.8.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1091 (1.1K) [text/plain]\n",
      "Saving to: ‚Äòstates.py‚Äô\n",
      "\n",
      "states.py           100%[===================>]   1.07K  --.-KB/s    in 0.004s  \n",
      "\n",
      "2021-02-02 03:04:16 (250 KB/s) - ‚Äòstates.py‚Äô saved [1091/1091]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://gist.githubusercontent.com/rugbyprof/76575b470b6772ce8fa0c49e23931d97/raw/eb731ce40f9c7c032f4db42e96889a3adbe54f8e/states.py -O states.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_params = {\n",
    "    \"lower_case\": True,\n",
    "    \"replace_emot\": True,\n",
    "    \"remove_punc\": True,\n",
    "    \"replace_unicode\": True,\n",
    "    \"replace_abbv\": True,\n",
    "    \"stopwords\": True,\n",
    "    \"stemming\": False,\n",
    "    \"lemmatization\": True,\n",
    "}\n",
    "mlflow.log_params(clean_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from states import states as states_map\n",
    "\n",
    "\n",
    "def clean_texts(texts, clean_params):\n",
    "    \"\"\"Cleans the given texts applying clean techniques specified in clean_params\n",
    "    Returns:\n",
    "        The given texts with clean techniques applied\n",
    "    \"\"\"\n",
    "    # check mutually exclusive parameters\n",
    "    assert not (clean_params[\"stemming\"] and clean_params[\"lemmatization\"])\n",
    "\n",
    "    # remove trailing newlines\n",
    "    texts = np.asarray([t.rstrip() for t in texts])\n",
    "\n",
    "    # apply cleaning techniques on copy of dataframe\n",
    "    if clean_params[\"lower_case\"]:\n",
    "        texts = np.asarray([t.lower() for t in texts])\n",
    "\n",
    "    if clean_params[\"replace_emot\"]:\n",
    "\n",
    "        def replace_emot(text):\n",
    "            # replace emoticons with meaning if present\n",
    "            results = emoticons(text)\n",
    "            if results[\"flag\"]:\n",
    "                for location, meaning in zip(results[\"location\"], results[\"mean\"]):\n",
    "                    start, end = location\n",
    "                    # fix \"andry\" spelling mistake\n",
    "                    # https://github.com/NeelShah18/emot/pull/19/files\n",
    "                    meaning = meaning.replace(\"andry\", \"angry\")\n",
    "                    text = f\"{text[:start]} {meaning} {text[end+1:]}\"\n",
    "            return text\n",
    "\n",
    "        texts = np.asarray([replace_emot(t) for t in texts])\n",
    "\n",
    "    if clean_params[\"remove_punc\"]:\n",
    "        # ‚Ä¶ not recognized as puncuation, so remove it manually\n",
    "        texts = np.asarray([strip_punctuation(t.replace(\"‚Ä¶\", \"\")) for t in texts])\n",
    "\n",
    "    if clean_params[\"replace_unicode\"]:\n",
    "        texts = np.asarray([unidecode(t) for t in texts])\n",
    "\n",
    "    if clean_params[\"replace_abbv\"]:\n",
    "        # use utf-sig to fix escape characters\n",
    "        with open(\"slang.txt\", \"r\", encoding=\"utf-8-sig\") as f:\n",
    "            lines = f.readlines()\n",
    "        abbv_pairs = [tuple(line.split(maxsplit=1)) for line in lines]\n",
    "        # remove trailing newlines\n",
    "        abbv_map = {\n",
    "            # \\xa0 - for some reason latin spaces are present, replace with normal spaces.\n",
    "            abbv: full.rstrip().replace(\"\\xa0\", \"\")\n",
    "            for abbv, full in abbv_pairs\n",
    "        }\n",
    "        # additional abbreviation entries\n",
    "        abbv_map.update(\n",
    "            {\n",
    "                \"em\": \"them\",\n",
    "                \"v\": \"very\",\n",
    "            }\n",
    "        )\n",
    "        # expand  US state abbreviations\n",
    "        abbv_map.update(\n",
    "            {code.lower(): name.lower() for code, name in states_map.items()}\n",
    "        )\n",
    "        texts = np.asarray([replace(t, abbv_map) for t in texts])\n",
    "\n",
    "    if clean_params[\"stopwords\"]:\n",
    "        texts = np.asarray([remove_stopwords(t) for t in texts])\n",
    "    if clean_params[\"stemming\"]:\n",
    "        texts = np.asarray([stem_text(t) for t in texts])\n",
    "    if clean_params[\"lemmatization\"]:\n",
    "\n",
    "        def lemmatize(text):\n",
    "            lemma_map = {str(w): w.lemmatize() for w in TextBlob(text).words}\n",
    "            return replace(text, lemma_map)\n",
    "\n",
    "        texts = np.asarray([lemmatize(t) for t in texts])\n",
    "\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.6 s, sys: 190 ms, total: 23.8 s\n",
      "Wall time: 23.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clean_train_texts = clean_texts(train_texts, clean_params)\n",
    "clean_test_texts = clean_texts(test_texts, clean_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm slang.txt states.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Inspect the clean text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting text into vectors**:\n",
    "- `count` - Use the word count to vectorize text. Uses SVD to condense sparse vectors generated. [[5]](https://stackoverflow.com/a/34726420)\n",
    "- `tfidf` - Use tf-idf to vectorize text. Uses SVD to condense sparse vectors generated. [[5]](https://stackoverflow.com/a/34726420)\n",
    "- `fasttext` - Use pretrained english fasttext model to vectorize text. [[6]](https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md)\n",
    "\n",
    "> Out of an interest for time, `word2vec` is not included as`word2vec` vectors are significantly worst as compared to `fasttext` [[3]](https://github.com/RaRe-Technologies/gensim/blob/ba1ce894a5192fc493a865c535202695bb3c0424/docs/notebooks/Word2Vec_FastText_Comparison.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load pretrained fastext vectors pretrained on common crawl dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 905 ms, sys: 3.27 s, total: 4.17 s\n",
      "Wall time: 5.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<minio.datatypes.Object at 0x7f3eef614f98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# pull pretrained vectors from MINIO cache\n",
    "minio.fget_object(\n",
    "    bucket_name=\"cache\",\n",
    "    object_name=\"pretrained/fasttext/cc.en.bin\",\n",
    "    file_path=\"cc.en.bin\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.2 s, sys: 13.4 s, total: 1min 7s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "fasttext_vecs = load_facebook_vectors(\"cc.en.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute max no. of words per data example\n",
    "max_n_words = max(\n",
    "    [len(t.split()) for t in np.concatenate((clean_train_texts, clean_test_texts))]\n",
    ")\n",
    "vectorize_params = {\n",
    "    \"vectorize_method\": \"fasttext\",\n",
    "    \"vector_shape\": (max_n_words, 300),\n",
    "}\n",
    "# mlflow.log_params(vectorize_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_texts(texts, corpus_texts, method, vector_shape):\n",
    "    \"\"\"\n",
    "    Vectorize the given texts into 2D feature matrix using the given method.\n",
    "    Args:\n",
    "        texts: Iterable collection of texts to vectorize.\n",
    "        corpus_texts: Vectorization methods are allowed to fit on this corpus.\n",
    "        method: Name of the method to use for vectorization\n",
    "        vector_shape: Shape of the 2D feature matrix generated for each data example\n",
    "            in the form (n_words, n_features)\n",
    "    Returns vector representation of the given texts.\n",
    "    \"\"\"\n",
    "\n",
    "    if method in [\"count\", \"tfidf\"]:\n",
    "        if method == \"count\":\n",
    "            count = CountVectorizer()\n",
    "            count.fit(corpus_texts)\n",
    "            sparse_vecs = count.transform(texts)\n",
    "            # TODO: expand dims\n",
    "        elif method == \"tfidf\":\n",
    "            tfidf = TfidfVectorizer()\n",
    "            tfidf.fit(corpus_texts)\n",
    "            sparse_vecs = tfidf.transform(texts)\n",
    "        # use svd to condense vectors to match target vector len\n",
    "        svd = TruncatedSVD(n_components=vector_shape[1])\n",
    "        text_vecs = svd.fit_transform(sparse_vecs)\n",
    "        # since both count and tfidf are bag of words representations, add the missing\n",
    "        # word dimension here: (examples, features) -> (examples, word, features)\n",
    "        text_vecs = np.expand_dims(text_vecs, axis=1)\n",
    "    elif method == \"fasttext\":\n",
    "\n",
    "        def vectorize_fasttext(text):\n",
    "            # convert only the the first vector_shape[0] words\n",
    "            convert_words = text.split()[: vector_shape[0]]\n",
    "            # handle case where convert_words are empty\n",
    "            if len(convert_words) <= 0:\n",
    "                convert_words = [\"???\"]\n",
    "            word_vecs = [fasttext_vecs[w] for w in convert_words]\n",
    "            return np.asarray(word_vecs)\n",
    "\n",
    "        text_vecs = [vectorize_fasttext(t) for t in texts]\n",
    "        # pad words dimension to match vector_shape[0]\n",
    "        text_vecs = [\n",
    "            np.pad(\n",
    "                v, [(0, max(0, vector_shape[0] - v.shape[0])), (0, 0)], mode=\"constant\"\n",
    "            )\n",
    "            for v in text_vecs\n",
    "        ]\n",
    "        text_vecs = np.asarray(text_vecs)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Vectorization method not supported: {method}\")\n",
    "\n",
    "    # pad the text vec with zeros if we dont meet target vector shape\n",
    "    pad_words_len = max(0, vector_shape[0] - text_vecs.shape[1])\n",
    "    pad_features_len = max(0, vector_shape[1] - text_vecs.shape[2])\n",
    "    text_vecs = np.pad(\n",
    "        text_vecs, [(0, 0), (0, pad_words_len), (0, pad_features_len)], mode=\"constant\"\n",
    "    )\n",
    "    return text_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.34 s, sys: 533 ms, total: 3.87 s\n",
      "Wall time: 3.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_text_vecs = vectorize_texts(\n",
    "    clean_train_texts,\n",
    "    corpus_texts=clean_train_texts,\n",
    "    method=vectorize_params[\"vectorize_method\"],\n",
    "    vector_shape=vectorize_params[\"vector_shape\"],\n",
    ")\n",
    "\n",
    "test_text_vecs = vectorize_texts(\n",
    "    clean_test_texts,\n",
    "    corpus_texts=clean_test_texts,\n",
    "    method=vectorize_params[\"vectorize_method\"],\n",
    "    vector_shape=vectorize_params[\"vector_shape\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2649"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# free memory used to store vectors\n",
    "del fasttext_vecs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf cc.en.bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Inspect the vectors derived form text:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To combat the class imbalance issue we can resample the training set [[7]](https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb):\n",
    "- `oversample` : Use Random Oversampling to duplicate the data examples for Emojis smaller no. of examples to match the majority class.\n",
    "- `undersample`: Use Random Undersampling to undersample the data examples for the Majority Emoji cass to match the minority class.\n",
    "- `SMOTE`: Interpolate new systhesised training examples between K nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_method = \"oversample\"\n",
    "# mlflow.log_param(\"sampling_method\", sampling_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(text_vecs, labels, method):\n",
    "    \"\"\"\n",
    "    Resample data using the following resampling method to resolve class imbalance.\n",
    "    Args:\n",
    "        text_vecs: Text Vectors in the\n",
    "        method: The resampling method to use.\n",
    "    Returns:\n",
    "        The resampled texts and labels\n",
    "    \"\"\"\n",
    "    resamplers = {\n",
    "        \"oversample\": RandomOverSampler(),\n",
    "        \"undersample\": RandomUnderSampler(),\n",
    "        \"smote\": SMOTE(),\n",
    "    }\n",
    "\n",
    "    if method not in resamplers:\n",
    "        raise NotImplementedError(f\"Resampling method not supported: {method}\")\n",
    "    resampler = resamplers[method]\n",
    "    # flatten word, features dimensions into features dimension\n",
    "    # as imblearn only supports 2D as inputs\n",
    "    vector_shape = text_vecs.shape[1:]\n",
    "    flat_text_vecs = np.reshape(text_vecs, (len(text_vecs), -1))\n",
    "    flat_text_vecs, labels = resampler.fit_resample(flat_text_vecs, labels)\n",
    "    # restore word, features dimensions\n",
    "    text_vecs = np.reshape(flat_text_vecs, (len(flat_text_vecs),) + vector_shape)\n",
    "    return text_vecs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text_vecs_sampled, train_labels_sampled = resample_data(\n",
    "    train_text_vecs, train_labels, \"oversample\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training label distribution to check that  class imbalance issue has been resolved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7f3eef2c5b70>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(kind=\"count\", x=\"Label\", data=pd.DataFrame(train_labels_sampled))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 ‚Äì Develop a Sentiment Analysis Modesl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_fn(name, **params):\n",
    "    \"\"\"Return a layer performing the activation func with the given name with the given params \"\"\"\n",
    "    # remove activation name prefix\n",
    "    params = {param_name.replace(f\"{name}_\", \"\"): v for param_name, v in params.items()}\n",
    "\n",
    "    if name == \"tanh\":\n",
    "        return partial(tanh, **params)\n",
    "    elif name == \"selu\":\n",
    "        return partial(selu, **params)\n",
    "    elif name == \"relu\":\n",
    "        return partial(relu, **params)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Activation function {name} not implemented.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier(\n",
    "    in_op,\n",
    "    n_dense_units=128,\n",
    "    n_classes=10,\n",
    "    use_batch_norm=True,\n",
    "    dropout_prob=0.0,\n",
    "    l2_reg=None,\n",
    "    dense_activation=\"relu\",\n",
    "    **activation_params,\n",
    "):\n",
    "    \"\"\"Append a dense classfier block to the given in_op\"\"\"\n",
    "    x = in_op\n",
    "\n",
    "    # disable hidden dense layer if n_dense_units < 1\n",
    "    if n_dense_units >= 1:\n",
    "        x = Dense(\n",
    "            units=n_dense_units,\n",
    "            kernel_regularizer=None if l2_reg is None else l2(l=l2_reg),\n",
    "        )(x)\n",
    "\n",
    "    if use_batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    x = Activation(activation_fn(dense_activation, **activation_params))(x)\n",
    "    # classifier output layer\n",
    "    x = Dense(\n",
    "        units=n_classes,\n",
    "        activation=\"softmax\",\n",
    "        kernel_regularizer=None if l2_reg is None else l2(l=l2_reg),\n",
    "    )(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_block(\n",
    "    in_op,\n",
    "    rnn_cell=\"lstm\",\n",
    "    n_rnn_units=64,\n",
    "    rnn_activation=\"tanh\",\n",
    "    use_layer_norm=True,\n",
    "    return_sequences=False,\n",
    "    dropout_prob=0.0,\n",
    "    l2_reg=None,\n",
    "    **activation_params,\n",
    "):\n",
    "    rnn_params = {\n",
    "        \"units\": n_rnn_units,\n",
    "        \"activation\": activation_fn(name=rnn_activation, **activation_params),\n",
    "        \"recurrent_dropout\": dropout_prob,\n",
    "        \"kernel_regularizer\": None if l2_reg is None else l2(l=l2_reg),\n",
    "        \"return_sequences\": return_sequences,\n",
    "    }\n",
    "\n",
    "    x = in_op\n",
    "    if rnn_cell == \"lstm\":\n",
    "        x = LSTM(**rnn_params)(x)\n",
    "    elif rnn_cell == \"gru\":\n",
    "        x = GRU(**rnn_params)(x)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unsupported RNN cell: {rnn_cell}\")\n",
    "\n",
    "    if use_layer_norm:\n",
    "        x = LayerNormalization()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Training and Validation Accuracy & Loss Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "# model.save('text_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Training and Validation Accuracy & Loss Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "# model.save('text_model_2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 ‚Äì Evaluate the Model using Testing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model #1 (replicate where necessary for other models)\n",
    "# model.load_weights('text_model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Best Model\n",
    "# model.save('text_model_best.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 ‚Äì Use the Best Model to make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('text_model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the user input\n",
    "# text_input = np.array([input()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the user input into numeric tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model output using predict function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- [1] Failure of Classification Accuracy for Imbalanced Class Distributions. (2021, January 21). Retrieved from https://machinelearningmastery.com/failure-of-accuracy-for-imbalanced-class-distributions  \n",
    "- [2] sudalairajkumar. (2019). Getting started with Text Preprocessing. Kaggle. Retrieved from https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing\n",
    "- [3] RaRe-Technologies. (2021, January 28). gensim. Retrieved from https://github.com/RaRe-Technologies/gensim/blob/ba1ce894a5192fc493a865c535202695bb3c0424/docs/notebooks/Word2Vec_FastText_Comparison.ipynb\n",
    "- [4] Symeonidis, S., Effrosynidis, D., & Arampatzis, A. (2018). A comparative evaluation of pre-processing techniques and their interactions for twitter sentiment analysis. Expert Syst. Appl., 110, 298‚Äì310. doi: 10.1016/j.eswa.2018.06.022\n",
    "- [5] is it possible Apply PCA on any Text Classification? (2021, January 31). Retrieved from https://stackoverflow.com/questions/34725726/is-it-possible-apply-pca-on-any-text-classification\n",
    "- [6] facebookresearch. (2021, February 01). fastText. Retrieved from https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md\n",
    "- [7] Badr, W. (2020). Having an Imbalanced Dataset? Here Is How You Can Fix It. Towards Data Science. Retrieved from https://towardsdatascience.com/having-an-imbalanced-dataset-here-is-how-you-can-solve-it-1640568947eb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "autosnapshot": false,
   "docker_image": "core.harbor.mrzzy.co/kf-jupyter/tf-gpu-dl-plugged:0.4.0",
   "experiment": {
    "id": "new",
    "name": "test2"
   },
   "experiment_name": "test2",
   "katib_metadata": {
    "algorithm": {
     "algorithmName": "grid"
    },
    "maxFailedTrialCount": 3,
    "maxTrialCount": 12,
    "objective": {
     "objectiveMetricName": "",
     "type": "minimize"
    },
    "parallelTrialCount": 3,
    "parameters": []
   },
   "katib_run": false,
   "pipeline_description": "",
   "pipeline_name": "test",
   "snapshot_volumes": false,
   "steps_defaults": [
    "label:uses-minio:true",
    "label:uses-mlflow:true"
   ],
   "volume_access_mode": "rwm",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
