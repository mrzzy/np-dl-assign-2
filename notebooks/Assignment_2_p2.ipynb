{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 2 - Character Generator Model (Problem 2)</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Develop a English Language Model RNN capable of generating semi-coherent English sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use perplexity as a validation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use pretrained Transformer-XL  model from https://github.com/kimiyoung/transformer-xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoformat code on cell run.\n",
    "%load_ext lab_black\n",
    "# autoreload imported modules on change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import the Required Packages\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from git import Repo\n",
    "from unidecode import unidecode\n",
    "from minio import Minio\n",
    "from pprint import pprint\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical, Sequence\n",
    "from modeling import (\n",
    "    dense_classifier,\n",
    "    rnn_block,\n",
    "    compile_callbacks,\n",
    "    build_model,\n",
    "    train_eval_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure access to MLFlow by setting the following environment variables:\n",
    "- `MLFLOW_TRACKING_URI` - URL to the MLFlow Tracking server.\n",
    "- `MLFLOW_S3_ENDPOINT_URL` - URL to the MLFlow S3 Backend Store\n",
    "- `MLFLOW_EXPERIMENT` - Optional. The name of the MLFlow experiment to log to.\n",
    "- `MINIO_HOST` - End to the Minio S3 Store.\n",
    "- `AWS_ACCESS_KEY_ID` - MLFlow S3 backend store Avectorsccess Key ID.\n",
    "- `AWS_SECRET_ACCESS_KEY` - MLFlow S3 backend store secret access key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TF_FORCE_GPU_ALLOW_GROWTH` -  Force Tensorflow to allocate GPU memory dynamically\n",
    "instead of of all at once as a workaround for this\n",
    "[cuDNN failed to initialize issue](https://github.com/tensorflow/tensorflow/issues/24828)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
     ]
    }
   ],
   "source": [
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start MLFlow run with the name of the commit as fthe run name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(os.environ.get(\"MLFLOW_EXPERIMENT\", \"staging\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = Repo(search_parent_directories=True)\n",
    "mlflow.start_run(run_name=repo.head.commit.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup `minio` client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio = Minio(\n",
    "    endpoint=os.environ[\"MINIO_HOST\"],\n",
    "    access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    secure=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 – Data Loading and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load the `THE ADVENTURES OF SHERLOCK HOLMES` text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_DIR}/holmes.txt\") as f:\n",
    "    holmes_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek at the first 5 lines:\n",
    "- a unicode character `\\ufeff` has to be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffTHE ADVENTURES OF SHERLOCK HOLMES by SIR ARTHUR CONAN DOYLE',\n",
       " '',\n",
       " '   I. A Scandal in Bohemia',\n",
       " '  II. The Red-headed League',\n",
       " ' III. A Case of Identity',\n",
       " '  IV. The Boscombe Valley Mystery']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holmes_text.splitlines()[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No. of unique characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '\"' '&' \"'\" '(' ')' ',' '-' '.' '/' '0' '1' '2' '3' '4' '5'\n",
      " '6' '7' '8' '9' ':' ';' '?' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K'\n",
      " 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'a' 'b' 'c'\n",
      " 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u'\n",
      " 'v' 'w' 'x' 'y' 'z' 'à' 'â' 'è' 'é' '\\ufeff']\n",
      "no. of unique characters: 81\n"
     ]
    }
   ],
   "source": [
    "unique_chars = np.unique(list(holmes_text))\n",
    "print(unique_chars)\n",
    "# -1 for the `\\ufeff` character to be removed.\n",
    "n_unique_chars = len(unique_chars) - 1\n",
    "print(\"no. of unique characters:\", n_unique_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace unicode characters with ASCII ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_holmes_text = unidecode(holmes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE ADVENTURES OF SHERLOCK HOLMES by SIR ARTHUR CONAN DOYLE',\n",
       " '',\n",
       " '   I. A Scandal in Bohemia',\n",
       " '  II. The Red-headed League',\n",
       " ' III. A Case of Identity',\n",
       " '  IV. The Boscombe Valley Mystery']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_holmes_text.splitlines()[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile a mapping from between a number and a character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5} ...\n"
     ]
    }
   ],
   "source": [
    "charset = {char: i for i, char in enumerate(unique_chars)}\n",
    "print(dict(list(charset.items())[:6]), \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a character level language model that predicts the next character, text has to processed into:\n",
    "- context - List of preceding characters as the context the model base its prediction on.\n",
    "- character - The target prediction character given the preceding context that model is trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_params = {\n",
    "    \"context_len\": 100,\n",
    "    \"charset_size\": n_unique_chars,\n",
    "}\n",
    "mlflow.log_params(process_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_context_char_idx(text, process_params):\n",
    "    \"\"\"Generate index for context and char for training a character level language model\"\"\"\n",
    "    # calculate no. of examples: (context, char) pairs\n",
    "    context_char_len = process_params[\"context_len\"] + 1\n",
    "    n_examples = (len(text) - context_char_len)\n",
    "\n",
    "    ctx_positions = []\n",
    "    target_char_idxs = []\n",
    "    for i_example in range(n_examples):\n",
    "        # collect positions of where the context substr start and ends\n",
    "        context_start = i_example\n",
    "        context_end = context_start + process_params[\"context_len\"]\n",
    "        ctx_positions.append((context_start, context_end))\n",
    "\n",
    "        # collect index of target prediction char\n",
    "        target_char_idxs.append(context_end)\n",
    "\n",
    "    return ctx_positions, target_char_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_positions, target_char_idxs = generate_context_char_idx(holmes_text, process_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the generated indices into train, valid and test subsets, reserving 5000 examples for the test set, 2500 examples for the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 5000\n",
    "n_validation = 2500\n",
    "\n",
    "mlflow.log_param(\"test_size\", n_test)\n",
    "(\n",
    "    train_valid_ctx_positions,\n",
    "    test_ctx_positions,\n",
    "    train_valid_char_idxs,\n",
    "    test_char_idxs,\n",
    ") = train_test_split(ctx_positions, target_char_idxs, test_size=n_test)\n",
    "(\n",
    "    train_ctx_positions,\n",
    "    valid_ctx_positions,\n",
    "    train_char_idxs,\n",
    "    valid_char_idxs,\n",
    ") = train_test_split(\n",
    "    train_valid_ctx_positions, train_valid_char_idxs, test_size=n_validation\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Keras `Sequence` process at model runtime:\n",
    "- Extract the context and the target char  is computationally inexpensive, so the performance overhead should be minimal.\n",
    "- Since there is a significant amount of overlap between context characters, preprocessing the data now will result significant redundant RAM  usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextContext(Sequence):\n",
    "    def __init__(\n",
    "        self, ctx_positions, char_idxs, text, batch_size, charset, process_params\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create a text context data sequence useful for character level language models.\n",
    "\n",
    "        Args:\n",
    "            ctx_positions: List of positions of context in the text.\n",
    "            char_idxs: List of index of target predictio characters in the text.\n",
    "            text: Text to generate from.\n",
    "            batch_size: Size of the batchs of data to generate.\n",
    "            charset: Dictionary mapping character to int used to encode words as ints.\n",
    "            process_params: Additional Data processing parameters.\n",
    "        \"\"\"\n",
    "        self.ctx_positions = ctx_positions\n",
    "        self.char_idxs = char_idxs\n",
    "        assert len(ctx_positions) == len(char_idxs)\n",
    "\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        self.charset = charset\n",
    "        self.params = process_params\n",
    "\n",
    "    @property\n",
    "    def context_shape(self):\n",
    "        \"\"\"Return the shape of the processed context vector\"\"\"\n",
    "        return (self.params[\"context_len\"], self.params[\"charset_size\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        # no. of examples: (context, char) pairs\n",
    "        return len(self.ctx_positions) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, batch_idx):\n",
    "        \"\"\"Process text context data for the given batch at index batch_idx\"\"\"\n",
    "        contexts = []\n",
    "        target_chars = []\n",
    "\n",
    "        ctx_positions_batch = self.ctx_positions[\n",
    "            batch_idx * self.batch_size : (batch_idx + 1) * self.batch_size\n",
    "        ]\n",
    "        char_idxs_batch = self.char_idxs[\n",
    "            batch_idx * self.batch_size : (batch_idx + 1) * self.batch_size\n",
    "        ]\n",
    "\n",
    "        for context_pos, target_char_idx in zip(ctx_positions_batch, char_idxs_batch):\n",
    "\n",
    "            context_start, context_end = context_pos\n",
    "            # extract context vector\n",
    "            context = self.text[context_start:context_end]\n",
    "            context_int = [self.charset[c] for c in context]\n",
    "            contexts.append(context_int)\n",
    "\n",
    "            # extract target char\n",
    "            target_char = self.text[target_char_idx]\n",
    "            target_chars.append(self.charset[target_char])\n",
    "\n",
    "        n_classes = self.params[\"charset_size\"]\n",
    "        return (\n",
    "            to_categorical(contexts, num_classes=n_classes),\n",
    "            to_categorical(target_chars, num_classes=n_classes),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_holmes_ctx = TextContext(\n",
    "    ctx_positions=train_ctx_positions,\n",
    "    char_idxs=train_char_idxs,\n",
    "    batch_size=512,\n",
    "    text=clean_holmes_text,\n",
    "    charset=charset,\n",
    "    process_params=process_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.81 ms ± 220 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "train_holmes_ctx.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 – Develop Character Generator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100, 81)]         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100, 64)           37376     \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 100, 64)           128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 64)           33024     \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 100, 64)           128       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, 64)                128       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 81)                5265      \n",
      "=================================================================\n",
      "Total params: 109,073\n",
      "Trainable params: 109,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model(\n",
    "    input_shape=train_holmes_ctx.context_shape,\n",
    "    n_classes=process_params[\"charset_size\"],\n",
    ").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_holmes_ctx = TextContext(\n",
    "    ctx_positions=train_ctx_positions,\n",
    "    char_idxs=train_char_idxs,\n",
    "    batch_size=batch_size,\n",
    "    text=clean_holmes_text,\n",
    "    charset=charset,\n",
    "    process_params=process_params,\n",
    ")\n",
    "\n",
    "valid_holmes_ctx = TextContext(\n",
    "    ctx_positions=valid_ctx_positions,\n",
    "    char_idxs=valid_char_idxs,\n",
    "    batch_size=batch_size,\n",
    "    text=clean_holmes_text,\n",
    "    charset=charset,\n",
    "    process_params=process_params,\n",
    ")\n",
    "\n",
    "test_holmes_ctx = TextContext(\n",
    "    ctx_positions=test_ctx_positions,\n",
    "    char_idxs=test_char_idxs,\n",
    "    batch_size=batch_size,\n",
    "    text=clean_holmes_text,\n",
    "    charset=charset,\n",
    "    process_params=process_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = train_eval_model(\n",
    "    train_data=[train_holmes_ctx],\n",
    "    validation_data=valid_holmes_ctx,\n",
    "    test_data=[test_holmes_ctx],\n",
    "    build_model_fn=build_model,\n",
    "    n_classes=n_unique_chars,\n",
    "    tags={\n",
    "        \"project\": \"dl-assign-2\",\n",
    "        \"part\": \"1\",\n",
    "        \"model\": \"sentiment\",\n",
    "    },\n",
    "    input_shape=train_holmes_ctx.context_shape,\n",
    "    git_repo=Repo(search_parent_directories=True),\n",
    "    run_name=None,\n",
    "    epochs=60,\n",
    "    validation_split=0.1,\n",
    "    lr=1e-3,\n",
    "    optimizer=\"adam\",\n",
    "    sgd_momentum=0.9,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "    ],\n",
    "    reduce_lr_stuck=False,\n",
    "    reduce_lr_patience=10,\n",
    "    reduce_lr_factor=0.5,\n",
    "    batch_size=batch_size,\n",
    "    dropout_prob=0.3,\n",
    "    l2_reg=None,\n",
    "    rnn_cell=\"lstm\",\n",
    "    n_rnn_units=128,\n",
    "    n_rnn_layers=2,\n",
    "    rnn_activation=\"tanh\",\n",
    "    use_layer_norm=True,\n",
    "    n_dense_units=0,\n",
    "    use_batch_norm=True,\n",
    "    dense_activation=\"relu\",\n",
    ")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('chgen_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('chgen_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Best Model\n",
    "# model.save('chgen_model_best.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 – Use the Best Model to generate the characters / sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('chgen_model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the user input\n",
    "# text_input = np.array([input()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Best Model to generate 400 characters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
