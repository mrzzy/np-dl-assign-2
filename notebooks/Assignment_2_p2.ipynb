{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 2 - Character Generator Model (Problem 2)</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Develop a English Language Model RNN capable of generating semi-coherent English sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use perplexity as a validation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use pretrained Transformer-XL  model from https://github.com/kimiyoung/transformer-xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# autoformat code on cell run.\n",
    "%load_ext lab_black\n",
    "# autoreload imported modules on change\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import the Required Packages\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from git import Repo\n",
    "from unidecode import unidecode\n",
    "from minio import Minio\n",
    "from pprint import pprint\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from modeling import (\n",
    "    dense_classifier,\n",
    "    rnn_block,\n",
    "    compile_callbacks,\n",
    "    build_model,\n",
    "    train_eval_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure access to MLFlow by setting the following environment variables:\n",
    "- `MLFLOW_TRACKING_URI` - URL to the MLFlow Tracking server.\n",
    "- `MLFLOW_S3_ENDPOINT_URL` - URL to the MLFlow S3 Backend Store\n",
    "- `MLFLOW_EXPERIMENT` - Optional. The name of the MLFlow experiment to log to.\n",
    "- `MINIO_HOST` - End to the Minio S3 Store.\n",
    "- `AWS_ACCESS_KEY_ID` - MLFlow S3 backend store Avectorsccess Key ID.\n",
    "- `AWS_SECRET_ACCESS_KEY` - MLFlow S3 backend store secret access key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TF_FORCE_GPU_ALLOW_GROWTH` -  Force Tensorflow to allocate GPU memory dynamically\n",
    "instead of of all at once as a workaround for this\n",
    "[cuDNN failed to initialize issue](https://github.com/tensorflow/tensorflow/issues/24828)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
     ]
    }
   ],
   "source": [
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start MLFlow run with the name of the commit as fthe run name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(os.environ.get(\"MLFLOW_EXPERIMENT\", \"staging\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = Repo(search_parent_directories=True)\n",
    "mlflow.start_run(run_name=repo.head.commit.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup `minio` client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio = Minio(\n",
    "    endpoint=os.environ[\"MINIO_HOST\"],\n",
    "    access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    secure=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 – Data Loading and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Load the `THE ADVENTURES OF SHERLOCK HOLMES` text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_DIR}/holmes.txt\") as f:\n",
    "    holmes_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek at the first 5 lines:\n",
    "- a unicode character `\\ufeff` has to be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffTHE ADVENTURES OF SHERLOCK HOLMES by SIR ARTHUR CONAN DOYLE',\n",
       " '',\n",
       " '   I. A Scandal in Bohemia',\n",
       " '  II. The Red-headed League',\n",
       " ' III. A Case of Identity',\n",
       " '  IV. The Boscombe Valley Mystery']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holmes_text.splitlines()[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No. of unique characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n' ' ' '!' '\"' '&' \"'\" '(' ')' ',' '-' '.' '/' '0' '1' '2' '3' '4' '5'\n",
      " '6' '7' '8' '9' ':' ';' '?' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K'\n",
      " 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'a' 'b' 'c'\n",
      " 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u'\n",
      " 'v' 'w' 'x' 'y' 'z' 'à' 'â' 'è' 'é' '\\ufeff']\n",
      "no. of unique characters: 81\n"
     ]
    }
   ],
   "source": [
    "unique_chars = np.unique(list(holmes_text))\n",
    "print(unique_chars)\n",
    "# -1 for the `\\ufeff` character to be removed.\n",
    "n_unique_chars = len(unique_chars) - 1\n",
    "print(\"no. of unique characters:\", n_unique_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace unicode characters with ASCII ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_holmes_text = unidecode(holmes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE ADVENTURES OF SHERLOCK HOLMES by SIR ARTHUR CONAN DOYLE',\n",
       " '',\n",
       " '   I. A Scandal in Bohemia',\n",
       " '  II. The Red-headed League',\n",
       " ' III. A Case of Identity',\n",
       " '  IV. The Boscombe Valley Mystery']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_holmes_text.splitlines()[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile a mapping from between a number and a character:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '&': 4, \"'\": 5} ...\n"
     ]
    }
   ],
   "source": [
    "charset = {char: i for i, char in enumerate(unique_chars)}\n",
    "print(dict(list(charset.items())[:6]), \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a character level language model that predicts the next character, text has to processed into:\n",
    "- context - List of preceding characters as the context the model base its prediction on.\n",
    "- character - The target prediction character given the preceding context that model is trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_params = {\n",
    "    \"context_len\": 500,\n",
    "    \"charset_size\": n_unique_chars,\n",
    "}\n",
    "mlflow.log_params(process_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Keras `Sequence` process data at model runtime:\n",
    "- Data preprocessing is computationally inexpensive, so the performance overhead should be minimal.\n",
    "- Since there is a significant amount of overlap between context characters, preprocessing the data now will result significant redundant RAM  usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextContext(Sequence):\n",
    "    def __init__(self, text, batch_size, charset, process_params):\n",
    "        \"\"\"\n",
    "        Create a text context data sequence useful for character level language models.\n",
    "\n",
    "        Args:\n",
    "            text: Text to generate from.\n",
    "            batch_size: No. of batchs to generate.\n",
    "            charset: Dictionary mapping character to int.\n",
    "            process_params: Data processing parameters\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        self.charset = charset\n",
    "        self.params = process_params\n",
    "\n",
    "    @property\n",
    "    def context_shape(self):\n",
    "        \"\"\"Return the shape of the processed context vector\"\"\"\n",
    "        return (self.params[\"context_len\"], self.params[\"charset_size\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        # no. of examples: (context, char) pairs\n",
    "        context_char_len = self.params[\"context_len\"] + 1\n",
    "        n_examples = (len(self.text) - context_char_len) + 1\n",
    "        return n_examples // self.batch_size\n",
    "\n",
    "    def __getitem__(self, batch_idx):\n",
    "        \"\"\"Process text context data for the given batch at index batch_idx\"\"\"\n",
    "        contexts = []\n",
    "        target_chars = []\n",
    "\n",
    "        for i_example in range(self.batch_size):\n",
    "            # calculate position of where the context vector start and ends\n",
    "            context_start = batch_idx * self.batch_size + i_example\n",
    "            context_end = context_start + self.params[\"context_len\"]\n",
    "            # extract context vector\n",
    "            context = self.text[context_start:context_end]\n",
    "            context_int = [self.charset[c] for c in context]\n",
    "            # one hot encode the context\n",
    "            ctx_one_hot = to_categorical(\n",
    "                context_int, num_classes=self.params[\"charset_size\"]\n",
    "            )\n",
    "            contexts.append(ctx_one_hot)\n",
    "\n",
    "            # use character right after context vector as target predict character\n",
    "            target_char = self.text[context_end]\n",
    "            target_chars.append(target_char)\n",
    "\n",
    "        return np.asarray(contexts), np.asarray(target_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "holmes_ctx = TextContext(\n",
    "    batch_size=32,\n",
    "    text=clean_holmes_text,\n",
    "    charset=charset,\n",
    "    process_params=process_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.42 ms ± 117 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "holmes_ctx.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 500, 81)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_batch, char_batch = holmes_ctx.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 – Develop Character Generator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 500, 81)]         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 500, 64)           37376     \n",
      "_________________________________________________________________\n",
      "layer_normalization (LayerNo (None, 500, 64)           128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 500, 64)           33024     \n",
      "_________________________________________________________________\n",
      "layer_normalization_1 (Layer (None, 500, 64)           128       \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "layer_normalization_2 (Layer (None, 64)                128       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 81)                5265      \n",
      "=================================================================\n",
      "Total params: 109,073\n",
      "Trainable params: 109,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "build_model(\n",
    "    input_shape=holmes_ctx.context_shape,\n",
    "    n_classes=process_params[\"charset_size\"],\n",
    ").summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('chgen_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('chgen_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Best Model\n",
    "# model.save('chgen_model_best.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 – Use the Best Model to generate the characters / sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('chgen_model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the user input\n",
    "# text_input = np.array([input()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Best Model to generate 400 characters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
