{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-bordered\">\n",
    "    <tr>\n",
    "        <th style=\"text-align:center; width:25%\"><img src='https://www.np.edu.sg/PublishingImages/Pages/default/odp/ICT.jpg' style=\"width: 250px; height: 125px; \"></th>\n",
    "        <th style=\"text-align:center;\"><h1>Deep Learning</h1><h2>Assignment 2 - Character Generator Model (Problem 2)</h2><h3>AY2020/21 Semester</h3></th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective: Develop a English Language Model RNN capable of generating semi-coherent English sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use perplexity as a validation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Use pretrained Transformer-XL  model from https://github.com/kimiyoung/transformer-xl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "# Import the Required Packages\n",
    "import os\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from git import Repo\n",
    "from unidecode import unidecode\n",
    "from minio import Minio\n",
    "from zipfile import ZipFile\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    LeakyReLU,\n",
    "    ReLU,\n",
    "    LSTM,\n",
    "    GRU,\n",
    "    BatchNormalization,\n",
    "    LayerNormalization,\n",
    "    Dense,\n",
    ")\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure access to MLFlow by setting the following environment variables:\n",
    "- `MLFLOW_TRACKING_URI` - URL to the MLFlow Tracking server.\n",
    "- `MLFLOW_S3_ENDPOINT_URL` - URL to the MLFlow S3 Backend Store\n",
    "- `MLFLOW_EXPERIMENT` - Optional. The name of the MLFlow experiment to log to.\n",
    "- `MINIO_HOST` - End to the Minio S3 Store.\n",
    "- `AWS_ACCESS_KEY_ID` - MLFlow S3 backend store Avectorsccess Key ID.\n",
    "- `AWS_SECRET_ACCESS_KEY` - MLFlow S3 backend store secret access key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TF_FORCE_GPU_ALLOW_GROWTH` -  Force Tensorflow to allocate GPU memory dynamically\n",
    "instead of of all at once as a workaround for this\n",
    "[cuDNN failed to initialize issue](https://github.com/tensorflow/tensorflow/issues/24828)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TF_FORCE_GPU_ALLOW_GROWTH=true\n"
     ]
    }
   ],
   "source": [
    "%env TF_FORCE_GPU_ALLOW_GROWTH=true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start MLFlow run with the name of the commit as fthe run name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(os.environ.get(\"MLFLOW_EXPERIMENT\", \"staging\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActiveRun: >"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo = Repo(search_parent_directories=True)\n",
    "mlflow.start_run(run_name=repo.head.commit.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup `minio` client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "minio = Minio(\n",
    "    endpoint=os.environ[\"MINIO_HOST\"],\n",
    "    access_key=os.environ[\"AWS_ACCESS_KEY_ID\"],\n",
    "    secret_key=os.environ[\"AWS_SECRET_ACCESS_KEY\"],\n",
    "    secure=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 â€“ Data Loading and Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `THE ADVENTURES OF SHERLOCK HOLMES` text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_DIR}/holmes.txt\") as f:\n",
    "    holmes_text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a peek at the first 5 lines:\n",
    "- a unicode character `\\ufeff` has to be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\ufeffTHE ADVENTURES OF SHERLOCK HOLMES by SIR ARTHUR CONAN DOYLE',\n",
       " '',\n",
       " '   I. A Scandal in Bohemia',\n",
       " '  II. The Red-headed League',\n",
       " ' III. A Case of Identity']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holmes_text.splitlines()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace unicode characters with ASCII ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_holmes_text = unidecode(holmes_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THE ADVENTURES OF SHERLOCK HOLMES by SIR ARTHUR CONAN DOYLE',\n",
       " '',\n",
       " '   I. A Scandal in Bohemia',\n",
       " '  II. The Red-headed League',\n",
       " ' III. A Case of Identity']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_holmes_text.splitlines()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a character level language model that predicts the next character, text has to processed into:\n",
    "- context - List of preceding characters as the context the model base its prediction on.\n",
    "- character - The target prediction character given the preceding context that model is trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_params = {\n",
    "    \"context_len\": 10,\n",
    "}\n",
    "mlflow.log_params(process_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Keras `Sequence` process data at model runtime:\n",
    "- Data preprocessing is computationally inexpensive, so the performance overhead should be minimal.\n",
    "- Since there is a significant amount of overlap between context characters, preprocessing the data now will result significant redundant RAM  usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextContext(Sequence):\n",
    "    def __init__(self, text, batch_size, process_params):\n",
    "        \"\"\"\n",
    "        Create a text context data sequence useful for character level language models.\n",
    "\n",
    "        Args:\n",
    "            text: Text to generate from.\n",
    "            batch_size: No. of batchs to generate.\n",
    "            process_params: Data processing parameters\n",
    "        \"\"\"\n",
    "        self.text = text\n",
    "        self.batch_size = batch_size\n",
    "        self.context_len = process_params[\"context_len\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        # no. of examples: (context, char) pairs\n",
    "        context_char_len = self.context_len + 1\n",
    "        n_examples = (len(self.text) - context_char_len) + 1\n",
    "        return n_examples // self.batch_size\n",
    "\n",
    "    def __getitem__(self, batch_idx):\n",
    "        \"\"\"Process text context data for the given batch at index batch_idx\"\"\"\n",
    "        contexts = []\n",
    "        target_chars = []\n",
    "\n",
    "        for i_example in range(self.batch_size):\n",
    "            # calculate position of where the context vector start and ends\n",
    "            context_start = batch_idx * self.batch_size + i_example\n",
    "            context_end = context_start + self.context_len\n",
    "            # extract context vector\n",
    "            context = self.text[context_start:context_end]\n",
    "            contexts.append(context)\n",
    "\n",
    "            # use character right after context vector as target predict character\n",
    "            target_char = self.text[context_end]\n",
    "            target_chars.append(target_char)\n",
    "\n",
    "        return np.asarray(contexts), np.asarray(target_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "holmes_ctx = TextContext(\n",
    "    text=clean_holmes_text, batch_size=32, process_params=process_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.4 Âµs Â± 216 ns per loop (mean Â± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "context_batch, char_batch =  holmes_ctx.__getitem__(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 â€“ Develop Character Generator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define utility functions for building a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_classifier(\n",
    "    in_op,\n",
    "    n_dense_units=128,\n",
    "    n_classes=10,\n",
    "    use_batch_norm=True,\n",
    "    dropout_prob=0.0,\n",
    "    l2_reg=None,\n",
    "    dense_activation=\"relu\",\n",
    "    **activation_params,\n",
    "):\n",
    "    \"\"\"Append a dense classfier block to the given in_op\"\"\"\n",
    "    x = in_op\n",
    "\n",
    "    # disable hidden dense layer if n_dense_units < 1\n",
    "    if n_dense_units >= 1:\n",
    "        x = Dense(\n",
    "            units=n_dense_units,\n",
    "            kernel_regularizer=None if l2_reg is None else l2(l=l2_reg),\n",
    "        )(x)\n",
    "\n",
    "        if use_batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "        x = Activation(dense_activation)(x)\n",
    "    # classifier output layer\n",
    "    x = Dense(\n",
    "        units=n_classes,\n",
    "        activation=\"softmax\",\n",
    "        kernel_regularizer=None if l2_reg is None else l2(l=l2_reg),\n",
    "    )(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_block(\n",
    "    in_op,\n",
    "    rnn_cell=\"lstm\",\n",
    "    n_rnn_units=64,\n",
    "    rnn_activation=\"tanh\",\n",
    "    use_layer_norm=True,\n",
    "    return_sequences=False,\n",
    "    dropout_prob=0.0,\n",
    "    l2_reg=None,\n",
    "    **activation_params,\n",
    "):\n",
    "    rnn_params = {\n",
    "        \"units\": n_rnn_units,\n",
    "        \"activation\": rnn_activation,\n",
    "        \"recurrent_dropout\": dropout_prob,\n",
    "        \"kernel_regularizer\": None if l2_reg is None else l2(l=l2_reg),\n",
    "        \"return_sequences\": return_sequences,\n",
    "    }\n",
    "\n",
    "    x = in_op\n",
    "    if rnn_cell == \"lstm\":\n",
    "        x = LSTM(**rnn_params)(x)\n",
    "    elif rnn_cell == \"gru\":\n",
    "        x = GRU(**rnn_params)(x)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Unsupported RNN cell: {rnn_cell}\")\n",
    "\n",
    "    if use_layer_norm:\n",
    "        x = LayerNormalization()(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape=(process_params[\"context_len\"], 1),\n",
    "    n_classes=10,\n",
    "    n_dense_units=0,\n",
    "    use_batch_norm=True,\n",
    "    rnn_cell=\"lstm\",\n",
    "    n_rnn_layers=3,\n",
    "    n_rnn_units=64,\n",
    "    rnn_activation=\"tanh\",\n",
    "    dense_activation=\"relu\",\n",
    "    use_layer_norm=True,\n",
    "    **block_params\n",
    "):\n",
    "    in_op = Input(shape=input_shape)\n",
    "    x = in_op\n",
    "\n",
    "    for i_layer in range(1, n_rnn_layers + 1):\n",
    "        x = rnn_block(\n",
    "            in_op=x,\n",
    "            rnn_cell=rnn_cell,\n",
    "            n_rnn_units=n_rnn_units,\n",
    "            rnn_activation=rnn_activation,\n",
    "            use_layer_norm=use_layer_norm,\n",
    "            # return sequences except last rnn layer\n",
    "            return_sequences=True if i_layer < n_rnn_layers else False,\n",
    "            **block_params,\n",
    "        )\n",
    "\n",
    "    x = dense_classifier(\n",
    "        in_op=x,\n",
    "        n_classes=n_classes,\n",
    "        n_dense_units=n_dense_units,\n",
    "        use_batch_norm=use_batch_norm,\n",
    "        dense_activation=dense_activation,\n",
    "        **block_params,\n",
    "    )\n",
    "\n",
    "    return Model(\n",
    "        inputs=in_op,\n",
    "        outputs=x,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('chgen_model_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('chgen_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recommend the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Best Model\n",
    "# model.save('chgen_model_best.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 â€“ Use the Best Model to generate the characters / sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('chgen_model_best.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes the user input\n",
    "# text_input = np.array([input()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the Best Model to generate 400 characters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
